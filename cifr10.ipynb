{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifr10.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imswabhab/Projects-ML/blob/master/cifr10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZspMSALC8xm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "a396cd8f-fe51-4965-a128-72c9ff1294c4"
      },
      "source": [
        "#importing relevant libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import datetime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ0gkBhpDOUh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27b6f1b5-0b9c-41a4-9870-7fd5873565e6"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5H7aTghEMw2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ef3aa936-babb-4b7b-c552-004ba7899084"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(x_train,y_train),(x_test,y_test)= cifar10.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU8ooFuiE4Fw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "454fd8bb-d380-4533-b492-82bf4da28192"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEC8fhs0FDNl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14b88c0b-808d-4020-feb4-37967f74fe32"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_EEgABoFE3e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "bd05da48-70db-4ee2-e559-d1b60fba23ce"
      },
      "source": [
        "#visualizing random input\n",
        "i = 30023\n",
        "plt.imshow(x_train[i])\n",
        "print(y_train[i])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlbI1LokFS2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa6d29fb-fbb5-4511-e083-7f9cf239465f"
      },
      "source": [
        "x_train"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 59,  62,  63],\n",
              "         [ 43,  46,  45],\n",
              "         [ 50,  48,  43],\n",
              "         ...,\n",
              "         [158, 132, 108],\n",
              "         [152, 125, 102],\n",
              "         [148, 124, 103]],\n",
              "\n",
              "        [[ 16,  20,  20],\n",
              "         [  0,   0,   0],\n",
              "         [ 18,   8,   0],\n",
              "         ...,\n",
              "         [123,  88,  55],\n",
              "         [119,  83,  50],\n",
              "         [122,  87,  57]],\n",
              "\n",
              "        [[ 25,  24,  21],\n",
              "         [ 16,   7,   0],\n",
              "         [ 49,  27,   8],\n",
              "         ...,\n",
              "         [118,  84,  50],\n",
              "         [120,  84,  50],\n",
              "         [109,  73,  42]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[208, 170,  96],\n",
              "         [201, 153,  34],\n",
              "         [198, 161,  26],\n",
              "         ...,\n",
              "         [160, 133,  70],\n",
              "         [ 56,  31,   7],\n",
              "         [ 53,  34,  20]],\n",
              "\n",
              "        [[180, 139,  96],\n",
              "         [173, 123,  42],\n",
              "         [186, 144,  30],\n",
              "         ...,\n",
              "         [184, 148,  94],\n",
              "         [ 97,  62,  34],\n",
              "         [ 83,  53,  34]],\n",
              "\n",
              "        [[177, 144, 116],\n",
              "         [168, 129,  94],\n",
              "         [179, 142,  87],\n",
              "         ...,\n",
              "         [216, 184, 140],\n",
              "         [151, 118,  84],\n",
              "         [123,  92,  72]]],\n",
              "\n",
              "\n",
              "       [[[154, 177, 187],\n",
              "         [126, 137, 136],\n",
              "         [105, 104,  95],\n",
              "         ...,\n",
              "         [ 91,  95,  71],\n",
              "         [ 87,  90,  71],\n",
              "         [ 79,  81,  70]],\n",
              "\n",
              "        [[140, 160, 169],\n",
              "         [145, 153, 154],\n",
              "         [125, 125, 118],\n",
              "         ...,\n",
              "         [ 96,  99,  78],\n",
              "         [ 77,  80,  62],\n",
              "         [ 71,  73,  61]],\n",
              "\n",
              "        [[140, 155, 164],\n",
              "         [139, 146, 149],\n",
              "         [115, 115, 112],\n",
              "         ...,\n",
              "         [ 79,  82,  64],\n",
              "         [ 68,  70,  55],\n",
              "         [ 67,  69,  55]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[175, 167, 166],\n",
              "         [156, 154, 160],\n",
              "         [154, 160, 170],\n",
              "         ...,\n",
              "         [ 42,  34,  36],\n",
              "         [ 61,  53,  57],\n",
              "         [ 93,  83,  91]],\n",
              "\n",
              "        [[165, 154, 128],\n",
              "         [156, 152, 130],\n",
              "         [159, 161, 142],\n",
              "         ...,\n",
              "         [103,  93,  96],\n",
              "         [123, 114, 120],\n",
              "         [131, 121, 131]],\n",
              "\n",
              "        [[163, 148, 120],\n",
              "         [158, 148, 122],\n",
              "         [163, 156, 133],\n",
              "         ...,\n",
              "         [143, 133, 139],\n",
              "         [143, 134, 142],\n",
              "         [143, 133, 144]]],\n",
              "\n",
              "\n",
              "       [[[255, 255, 255],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         ...,\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[113, 120, 112],\n",
              "         [111, 118, 111],\n",
              "         [105, 112, 106],\n",
              "         ...,\n",
              "         [ 72,  81,  80],\n",
              "         [ 72,  80,  79],\n",
              "         [ 72,  80,  79]],\n",
              "\n",
              "        [[111, 118, 110],\n",
              "         [104, 111, 104],\n",
              "         [ 99, 106,  98],\n",
              "         ...,\n",
              "         [ 68,  75,  73],\n",
              "         [ 70,  76,  75],\n",
              "         [ 78,  84,  82]],\n",
              "\n",
              "        [[106, 113, 105],\n",
              "         [ 99, 106,  98],\n",
              "         [ 95, 102,  94],\n",
              "         ...,\n",
              "         [ 78,  85,  83],\n",
              "         [ 79,  85,  83],\n",
              "         [ 80,  86,  84]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 35, 178, 235],\n",
              "         [ 40, 176, 239],\n",
              "         [ 42, 176, 241],\n",
              "         ...,\n",
              "         [ 99, 177, 219],\n",
              "         [ 79, 147, 197],\n",
              "         [ 89, 148, 189]],\n",
              "\n",
              "        [[ 57, 182, 234],\n",
              "         [ 44, 184, 250],\n",
              "         [ 50, 183, 240],\n",
              "         ...,\n",
              "         [156, 182, 200],\n",
              "         [141, 177, 206],\n",
              "         [116, 149, 175]],\n",
              "\n",
              "        [[ 98, 197, 237],\n",
              "         [ 64, 189, 252],\n",
              "         [ 69, 192, 245],\n",
              "         ...,\n",
              "         [188, 195, 206],\n",
              "         [119, 135, 147],\n",
              "         [ 61,  79,  90]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 73,  79,  77],\n",
              "         [ 53,  63,  68],\n",
              "         [ 54,  68,  80],\n",
              "         ...,\n",
              "         [ 17,  40,  64],\n",
              "         [ 21,  36,  51],\n",
              "         [ 33,  48,  49]],\n",
              "\n",
              "        [[ 61,  68,  75],\n",
              "         [ 55,  70,  86],\n",
              "         [ 57,  79, 103],\n",
              "         ...,\n",
              "         [ 24,  48,  72],\n",
              "         [ 17,  35,  53],\n",
              "         [  7,  23,  32]],\n",
              "\n",
              "        [[ 44,  56,  73],\n",
              "         [ 46,  66,  88],\n",
              "         [ 49,  77, 105],\n",
              "         ...,\n",
              "         [ 27,  52,  77],\n",
              "         [ 21,  43,  66],\n",
              "         [ 12,  31,  50]]],\n",
              "\n",
              "\n",
              "       [[[189, 211, 240],\n",
              "         [186, 208, 236],\n",
              "         [185, 207, 235],\n",
              "         ...,\n",
              "         [175, 195, 224],\n",
              "         [172, 194, 222],\n",
              "         [169, 194, 220]],\n",
              "\n",
              "        [[194, 210, 239],\n",
              "         [191, 207, 236],\n",
              "         [190, 206, 235],\n",
              "         ...,\n",
              "         [173, 192, 220],\n",
              "         [171, 191, 218],\n",
              "         [167, 190, 216]],\n",
              "\n",
              "        [[208, 219, 244],\n",
              "         [205, 216, 240],\n",
              "         [204, 215, 239],\n",
              "         ...,\n",
              "         [175, 191, 217],\n",
              "         [172, 190, 216],\n",
              "         [169, 191, 215]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[207, 199, 181],\n",
              "         [203, 195, 175],\n",
              "         [203, 196, 173],\n",
              "         ...,\n",
              "         [135, 132, 127],\n",
              "         [162, 158, 150],\n",
              "         [168, 163, 151]],\n",
              "\n",
              "        [[198, 190, 170],\n",
              "         [189, 181, 159],\n",
              "         [180, 172, 147],\n",
              "         ...,\n",
              "         [178, 171, 160],\n",
              "         [175, 169, 156],\n",
              "         [175, 169, 154]],\n",
              "\n",
              "        [[198, 189, 173],\n",
              "         [189, 181, 162],\n",
              "         [178, 170, 149],\n",
              "         ...,\n",
              "         [195, 184, 169],\n",
              "         [196, 189, 171],\n",
              "         [195, 190, 171]]],\n",
              "\n",
              "\n",
              "       [[[229, 229, 239],\n",
              "         [236, 237, 247],\n",
              "         [234, 236, 247],\n",
              "         ...,\n",
              "         [217, 219, 233],\n",
              "         [221, 223, 234],\n",
              "         [222, 223, 233]],\n",
              "\n",
              "        [[222, 221, 229],\n",
              "         [239, 239, 249],\n",
              "         [233, 234, 246],\n",
              "         ...,\n",
              "         [223, 223, 236],\n",
              "         [227, 228, 238],\n",
              "         [210, 211, 220]],\n",
              "\n",
              "        [[213, 206, 211],\n",
              "         [234, 232, 239],\n",
              "         [231, 233, 244],\n",
              "         ...,\n",
              "         [220, 220, 232],\n",
              "         [220, 219, 232],\n",
              "         [202, 203, 215]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[150, 143, 135],\n",
              "         [140, 135, 127],\n",
              "         [132, 127, 120],\n",
              "         ...,\n",
              "         [224, 222, 218],\n",
              "         [230, 228, 225],\n",
              "         [241, 241, 238]],\n",
              "\n",
              "        [[137, 132, 126],\n",
              "         [130, 127, 120],\n",
              "         [125, 121, 115],\n",
              "         ...,\n",
              "         [181, 180, 178],\n",
              "         [202, 201, 198],\n",
              "         [212, 211, 207]],\n",
              "\n",
              "        [[122, 119, 114],\n",
              "         [118, 116, 110],\n",
              "         [120, 116, 111],\n",
              "         ...,\n",
              "         [179, 177, 173],\n",
              "         [164, 164, 162],\n",
              "         [163, 163, 161]]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CimH64vF070",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PIPutsAGG3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbUWLSCDGQAB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0798a572-f232-412b-c8e2-530f72090ec9"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       ...,\n",
              "       [9],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKIWmRb2GRuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting y_train an y_test to categorical inputs\n",
        "\n",
        "import keras\n",
        "y_train = keras.utils.to_categorical(y_train,categories)\n",
        "y_test = keras.utils.to_categorical(y_test,categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73jV268nGs6x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "39c17461-7388-4303-9915-3ed1e6f5eed7"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB2Ys0F4GxL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalizing x_test and x_train\n",
        "\n",
        "x_test = x_test/255\n",
        "x_trainm = x_train/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5lmSAl7HRQI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "47725422-c839-4fc7-e503-1e025a91fe86"
      },
      "source": [
        "x_test"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.61960787, 0.4392157 , 0.19215687],\n",
              "         [0.62352943, 0.43529412, 0.18431373],\n",
              "         [0.64705884, 0.45490196, 0.2       ],\n",
              "         ...,\n",
              "         [0.5372549 , 0.37254903, 0.14117648],\n",
              "         [0.49411765, 0.35686275, 0.14117648],\n",
              "         [0.45490196, 0.33333334, 0.12941177]],\n",
              "\n",
              "        [[0.59607846, 0.4392157 , 0.2       ],\n",
              "         [0.5921569 , 0.43137255, 0.15686275],\n",
              "         [0.62352943, 0.44705883, 0.1764706 ],\n",
              "         ...,\n",
              "         [0.53333336, 0.37254903, 0.12156863],\n",
              "         [0.49019608, 0.35686275, 0.1254902 ],\n",
              "         [0.46666667, 0.34509805, 0.13333334]],\n",
              "\n",
              "        [[0.5921569 , 0.43137255, 0.18431373],\n",
              "         [0.5921569 , 0.42745098, 0.12941177],\n",
              "         [0.61960787, 0.43529412, 0.14117648],\n",
              "         ...,\n",
              "         [0.54509807, 0.38431373, 0.13333334],\n",
              "         [0.50980395, 0.37254903, 0.13333334],\n",
              "         [0.47058824, 0.34901962, 0.12941177]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.26666668, 0.4862745 , 0.69411767],\n",
              "         [0.16470589, 0.39215687, 0.5803922 ],\n",
              "         [0.12156863, 0.34509805, 0.5372549 ],\n",
              "         ...,\n",
              "         [0.14901961, 0.38039216, 0.57254905],\n",
              "         [0.05098039, 0.2509804 , 0.42352942],\n",
              "         [0.15686275, 0.33333334, 0.49803922]],\n",
              "\n",
              "        [[0.23921569, 0.45490196, 0.65882355],\n",
              "         [0.19215687, 0.4       , 0.5803922 ],\n",
              "         [0.13725491, 0.33333334, 0.5176471 ],\n",
              "         ...,\n",
              "         [0.10196079, 0.32156864, 0.50980395],\n",
              "         [0.11372549, 0.32156864, 0.49411765],\n",
              "         [0.07843138, 0.2509804 , 0.41960785]],\n",
              "\n",
              "        [[0.21176471, 0.41960785, 0.627451  ],\n",
              "         [0.21960784, 0.4117647 , 0.58431375],\n",
              "         [0.1764706 , 0.34901962, 0.5176471 ],\n",
              "         ...,\n",
              "         [0.09411765, 0.3019608 , 0.4862745 ],\n",
              "         [0.13333334, 0.32941177, 0.5058824 ],\n",
              "         [0.08235294, 0.2627451 , 0.43137255]]],\n",
              "\n",
              "\n",
              "       [[[0.92156863, 0.92156863, 0.92156863],\n",
              "         [0.90588236, 0.90588236, 0.90588236],\n",
              "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
              "         ...,\n",
              "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
              "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
              "         [0.9098039 , 0.9098039 , 0.9098039 ]],\n",
              "\n",
              "        [[0.93333334, 0.93333334, 0.93333334],\n",
              "         [0.92156863, 0.92156863, 0.92156863],\n",
              "         [0.92156863, 0.92156863, 0.92156863],\n",
              "         ...,\n",
              "         [0.9254902 , 0.9254902 , 0.9254902 ],\n",
              "         [0.9254902 , 0.9254902 , 0.9254902 ],\n",
              "         [0.92156863, 0.92156863, 0.92156863]],\n",
              "\n",
              "        [[0.92941177, 0.92941177, 0.92941177],\n",
              "         [0.91764706, 0.91764706, 0.91764706],\n",
              "         [0.91764706, 0.91764706, 0.91764706],\n",
              "         ...,\n",
              "         [0.92156863, 0.92156863, 0.92156863],\n",
              "         [0.92156863, 0.92156863, 0.92156863],\n",
              "         [0.91764706, 0.91764706, 0.91764706]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.34117648, 0.3882353 , 0.34901962],\n",
              "         [0.16862746, 0.2       , 0.14509805],\n",
              "         [0.07450981, 0.09019608, 0.04313726],\n",
              "         ...,\n",
              "         [0.6627451 , 0.72156864, 0.7019608 ],\n",
              "         [0.7137255 , 0.77254903, 0.75686276],\n",
              "         [0.7372549 , 0.7921569 , 0.7882353 ]],\n",
              "\n",
              "        [[0.32156864, 0.3764706 , 0.32156864],\n",
              "         [0.18039216, 0.22352941, 0.14117648],\n",
              "         [0.14117648, 0.17254902, 0.08627451],\n",
              "         ...,\n",
              "         [0.68235296, 0.7411765 , 0.7176471 ],\n",
              "         [0.7254902 , 0.78431374, 0.76862746],\n",
              "         [0.73333335, 0.7921569 , 0.78431374]],\n",
              "\n",
              "        [[0.33333334, 0.39607844, 0.3254902 ],\n",
              "         [0.24313726, 0.29411766, 0.1882353 ],\n",
              "         [0.22745098, 0.2627451 , 0.14901961],\n",
              "         ...,\n",
              "         [0.65882355, 0.7176471 , 0.69803923],\n",
              "         [0.7058824 , 0.7647059 , 0.7490196 ],\n",
              "         [0.7294118 , 0.78431374, 0.78039217]]],\n",
              "\n",
              "\n",
              "       [[[0.61960787, 0.74509805, 0.87058824],\n",
              "         [0.61960787, 0.73333335, 0.85490197],\n",
              "         [0.54509807, 0.6509804 , 0.7607843 ],\n",
              "         ...,\n",
              "         [0.89411765, 0.90588236, 0.91764706],\n",
              "         [0.92941177, 0.9372549 , 0.9529412 ],\n",
              "         [0.93333334, 0.94509804, 0.9647059 ]],\n",
              "\n",
              "        [[0.6666667 , 0.78431374, 0.8980392 ],\n",
              "         [0.6745098 , 0.78039217, 0.8862745 ],\n",
              "         [0.5921569 , 0.6901961 , 0.7882353 ],\n",
              "         ...,\n",
              "         [0.9098039 , 0.9098039 , 0.9254902 ],\n",
              "         [0.9647059 , 0.9647059 , 0.98039216],\n",
              "         [0.9647059 , 0.96862745, 0.9843137 ]],\n",
              "\n",
              "        [[0.68235296, 0.7882353 , 0.88235295],\n",
              "         [0.6901961 , 0.78431374, 0.87058824],\n",
              "         [0.6156863 , 0.7019608 , 0.78039217],\n",
              "         ...,\n",
              "         [0.9019608 , 0.8980392 , 0.9098039 ],\n",
              "         [0.98039216, 0.9764706 , 0.9843137 ],\n",
              "         [0.9607843 , 0.95686275, 0.96862745]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.12156863, 0.15686275, 0.1764706 ],\n",
              "         [0.11764706, 0.15294118, 0.17254902],\n",
              "         [0.10196079, 0.13725491, 0.15686275],\n",
              "         ...,\n",
              "         [0.14509805, 0.15686275, 0.18039216],\n",
              "         [0.03529412, 0.05098039, 0.05490196],\n",
              "         [0.01568628, 0.02745098, 0.01960784]],\n",
              "\n",
              "        [[0.09019608, 0.13333334, 0.15294118],\n",
              "         [0.10588235, 0.14901961, 0.16862746],\n",
              "         [0.09803922, 0.14117648, 0.16078432],\n",
              "         ...,\n",
              "         [0.07450981, 0.07843138, 0.09411765],\n",
              "         [0.01568628, 0.02352941, 0.01176471],\n",
              "         [0.01960784, 0.02745098, 0.01176471]],\n",
              "\n",
              "        [[0.10980392, 0.16078432, 0.18431373],\n",
              "         [0.11764706, 0.16862746, 0.19607843],\n",
              "         [0.1254902 , 0.1764706 , 0.20392157],\n",
              "         ...,\n",
              "         [0.01960784, 0.02352941, 0.03137255],\n",
              "         [0.01568628, 0.01960784, 0.01176471],\n",
              "         [0.02745098, 0.03137255, 0.02745098]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.07843138, 0.05882353, 0.04705882],\n",
              "         [0.07450981, 0.05490196, 0.04313726],\n",
              "         [0.05882353, 0.05490196, 0.04313726],\n",
              "         ...,\n",
              "         [0.03921569, 0.03529412, 0.02745098],\n",
              "         [0.04705882, 0.04313726, 0.03529412],\n",
              "         [0.05098039, 0.04705882, 0.03921569]],\n",
              "\n",
              "        [[0.08235294, 0.0627451 , 0.05098039],\n",
              "         [0.07843138, 0.0627451 , 0.05098039],\n",
              "         [0.07058824, 0.06666667, 0.04705882],\n",
              "         ...,\n",
              "         [0.03921569, 0.03529412, 0.02745098],\n",
              "         [0.03921569, 0.03529412, 0.02745098],\n",
              "         [0.04705882, 0.04313726, 0.03529412]],\n",
              "\n",
              "        [[0.08235294, 0.0627451 , 0.05098039],\n",
              "         [0.08235294, 0.06666667, 0.04705882],\n",
              "         [0.07843138, 0.07058824, 0.04313726],\n",
              "         ...,\n",
              "         [0.04705882, 0.04313726, 0.03529412],\n",
              "         [0.04705882, 0.04313726, 0.03529412],\n",
              "         [0.05098039, 0.04705882, 0.03921569]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.12941177, 0.09803922, 0.05098039],\n",
              "         [0.13333334, 0.10196079, 0.05882353],\n",
              "         [0.13333334, 0.10196079, 0.05882353],\n",
              "         ...,\n",
              "         [0.10980392, 0.09803922, 0.20392157],\n",
              "         [0.11372549, 0.09803922, 0.22745098],\n",
              "         [0.09019608, 0.07843138, 0.16470589]],\n",
              "\n",
              "        [[0.12941177, 0.09803922, 0.05490196],\n",
              "         [0.13333334, 0.10196079, 0.05882353],\n",
              "         [0.13333334, 0.10196079, 0.05882353],\n",
              "         ...,\n",
              "         [0.10588235, 0.09411765, 0.20392157],\n",
              "         [0.10588235, 0.09411765, 0.21960784],\n",
              "         [0.09803922, 0.08627451, 0.18431373]],\n",
              "\n",
              "        [[0.12156863, 0.09019608, 0.04705882],\n",
              "         [0.1254902 , 0.09411765, 0.05098039],\n",
              "         [0.12941177, 0.09803922, 0.05490196],\n",
              "         ...,\n",
              "         [0.09411765, 0.09019608, 0.19607843],\n",
              "         [0.10196079, 0.09019608, 0.20784314],\n",
              "         [0.09803922, 0.07843138, 0.18431373]]],\n",
              "\n",
              "\n",
              "       [[[0.09803922, 0.15686275, 0.04705882],\n",
              "         [0.05882353, 0.14117648, 0.01176471],\n",
              "         [0.09019608, 0.16078432, 0.07058824],\n",
              "         ...,\n",
              "         [0.23921569, 0.32156864, 0.30588236],\n",
              "         [0.36078432, 0.44313726, 0.4392157 ],\n",
              "         [0.29411766, 0.34901962, 0.36078432]],\n",
              "\n",
              "        [[0.04705882, 0.09803922, 0.02352941],\n",
              "         [0.07843138, 0.14509805, 0.02745098],\n",
              "         [0.09411765, 0.14117648, 0.05882353],\n",
              "         ...,\n",
              "         [0.4509804 , 0.5254902 , 0.5411765 ],\n",
              "         [0.58431375, 0.65882355, 0.69411767],\n",
              "         [0.40784314, 0.45882353, 0.5137255 ]],\n",
              "\n",
              "        [[0.04705882, 0.09803922, 0.04313726],\n",
              "         [0.05882353, 0.11372549, 0.02352941],\n",
              "         [0.13333334, 0.15686275, 0.09411765],\n",
              "         ...,\n",
              "         [0.6039216 , 0.6745098 , 0.7137255 ],\n",
              "         [0.6156863 , 0.6862745 , 0.7529412 ],\n",
              "         [0.45490196, 0.5058824 , 0.5921569 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.39215687, 0.5058824 , 0.31764707],\n",
              "         [0.40392157, 0.5176471 , 0.32941177],\n",
              "         [0.40784314, 0.5254902 , 0.3372549 ],\n",
              "         ...,\n",
              "         [0.38039216, 0.5019608 , 0.32941177],\n",
              "         [0.38431373, 0.49411765, 0.32941177],\n",
              "         [0.35686275, 0.4745098 , 0.30980393]],\n",
              "\n",
              "        [[0.40392157, 0.5176471 , 0.3254902 ],\n",
              "         [0.40784314, 0.5137255 , 0.3254902 ],\n",
              "         [0.41960785, 0.5294118 , 0.34117648],\n",
              "         ...,\n",
              "         [0.39607844, 0.5176471 , 0.34117648],\n",
              "         [0.3882353 , 0.49803922, 0.32941177],\n",
              "         [0.36078432, 0.4745098 , 0.30980393]],\n",
              "\n",
              "        [[0.37254903, 0.49411765, 0.30588236],\n",
              "         [0.37254903, 0.48235294, 0.29803923],\n",
              "         [0.39607844, 0.5019608 , 0.31764707],\n",
              "         ...,\n",
              "         [0.3647059 , 0.4862745 , 0.3137255 ],\n",
              "         [0.37254903, 0.48235294, 0.31764707],\n",
              "         [0.36078432, 0.47058824, 0.3137255 ]]],\n",
              "\n",
              "\n",
              "       [[[0.28627452, 0.30588236, 0.29411766],\n",
              "         [0.38431373, 0.40392157, 0.44313726],\n",
              "         [0.3882353 , 0.41568628, 0.44705883],\n",
              "         ...,\n",
              "         [0.5294118 , 0.5882353 , 0.59607846],\n",
              "         [0.5294118 , 0.58431375, 0.6039216 ],\n",
              "         [0.79607844, 0.84313726, 0.8745098 ]],\n",
              "\n",
              "        [[0.27058825, 0.28627452, 0.27450982],\n",
              "         [0.32941177, 0.34901962, 0.38039216],\n",
              "         [0.26666668, 0.29411766, 0.31764707],\n",
              "         ...,\n",
              "         [0.33333334, 0.37254903, 0.34901962],\n",
              "         [0.2784314 , 0.32156864, 0.3137255 ],\n",
              "         [0.47058824, 0.52156866, 0.5294118 ]],\n",
              "\n",
              "        [[0.27058825, 0.28627452, 0.27450982],\n",
              "         [0.3529412 , 0.37254903, 0.39215687],\n",
              "         [0.24313726, 0.2784314 , 0.2901961 ],\n",
              "         ...,\n",
              "         [0.2901961 , 0.31764707, 0.27450982],\n",
              "         [0.20784314, 0.24313726, 0.21176471],\n",
              "         [0.24313726, 0.2901961 , 0.27058825]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.48235294, 0.5019608 , 0.3764706 ],\n",
              "         [0.5176471 , 0.5176471 , 0.4       ],\n",
              "         [0.5058824 , 0.5019608 , 0.39215687],\n",
              "         ...,\n",
              "         [0.42352942, 0.41960785, 0.34509805],\n",
              "         [0.24313726, 0.23529412, 0.21568628],\n",
              "         [0.10588235, 0.10588235, 0.10980392]],\n",
              "\n",
              "        [[0.4509804 , 0.4745098 , 0.35686275],\n",
              "         [0.48235294, 0.4862745 , 0.37254903],\n",
              "         [0.5058824 , 0.49411765, 0.3882353 ],\n",
              "         ...,\n",
              "         [0.4509804 , 0.45490196, 0.36862746],\n",
              "         [0.25882354, 0.25490198, 0.23137255],\n",
              "         [0.10588235, 0.10588235, 0.10588235]],\n",
              "\n",
              "        [[0.45490196, 0.47058824, 0.3529412 ],\n",
              "         [0.4745098 , 0.47843137, 0.36862746],\n",
              "         [0.5058824 , 0.5019608 , 0.39607844],\n",
              "         ...,\n",
              "         [0.45490196, 0.4509804 , 0.36862746],\n",
              "         [0.26666668, 0.25490198, 0.22745098],\n",
              "         [0.10588235, 0.10196079, 0.10196079]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3pD61eBHShX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9679e297-e330-4a9a-930b-ef6716b22ad5"
      },
      "source": [
        "x_train"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 59.,  62.,  63.],\n",
              "         [ 43.,  46.,  45.],\n",
              "         [ 50.,  48.,  43.],\n",
              "         ...,\n",
              "         [158., 132., 108.],\n",
              "         [152., 125., 102.],\n",
              "         [148., 124., 103.]],\n",
              "\n",
              "        [[ 16.,  20.,  20.],\n",
              "         [  0.,   0.,   0.],\n",
              "         [ 18.,   8.,   0.],\n",
              "         ...,\n",
              "         [123.,  88.,  55.],\n",
              "         [119.,  83.,  50.],\n",
              "         [122.,  87.,  57.]],\n",
              "\n",
              "        [[ 25.,  24.,  21.],\n",
              "         [ 16.,   7.,   0.],\n",
              "         [ 49.,  27.,   8.],\n",
              "         ...,\n",
              "         [118.,  84.,  50.],\n",
              "         [120.,  84.,  50.],\n",
              "         [109.,  73.,  42.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[208., 170.,  96.],\n",
              "         [201., 153.,  34.],\n",
              "         [198., 161.,  26.],\n",
              "         ...,\n",
              "         [160., 133.,  70.],\n",
              "         [ 56.,  31.,   7.],\n",
              "         [ 53.,  34.,  20.]],\n",
              "\n",
              "        [[180., 139.,  96.],\n",
              "         [173., 123.,  42.],\n",
              "         [186., 144.,  30.],\n",
              "         ...,\n",
              "         [184., 148.,  94.],\n",
              "         [ 97.,  62.,  34.],\n",
              "         [ 83.,  53.,  34.]],\n",
              "\n",
              "        [[177., 144., 116.],\n",
              "         [168., 129.,  94.],\n",
              "         [179., 142.,  87.],\n",
              "         ...,\n",
              "         [216., 184., 140.],\n",
              "         [151., 118.,  84.],\n",
              "         [123.,  92.,  72.]]],\n",
              "\n",
              "\n",
              "       [[[154., 177., 187.],\n",
              "         [126., 137., 136.],\n",
              "         [105., 104.,  95.],\n",
              "         ...,\n",
              "         [ 91.,  95.,  71.],\n",
              "         [ 87.,  90.,  71.],\n",
              "         [ 79.,  81.,  70.]],\n",
              "\n",
              "        [[140., 160., 169.],\n",
              "         [145., 153., 154.],\n",
              "         [125., 125., 118.],\n",
              "         ...,\n",
              "         [ 96.,  99.,  78.],\n",
              "         [ 77.,  80.,  62.],\n",
              "         [ 71.,  73.,  61.]],\n",
              "\n",
              "        [[140., 155., 164.],\n",
              "         [139., 146., 149.],\n",
              "         [115., 115., 112.],\n",
              "         ...,\n",
              "         [ 79.,  82.,  64.],\n",
              "         [ 68.,  70.,  55.],\n",
              "         [ 67.,  69.,  55.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[175., 167., 166.],\n",
              "         [156., 154., 160.],\n",
              "         [154., 160., 170.],\n",
              "         ...,\n",
              "         [ 42.,  34.,  36.],\n",
              "         [ 61.,  53.,  57.],\n",
              "         [ 93.,  83.,  91.]],\n",
              "\n",
              "        [[165., 154., 128.],\n",
              "         [156., 152., 130.],\n",
              "         [159., 161., 142.],\n",
              "         ...,\n",
              "         [103.,  93.,  96.],\n",
              "         [123., 114., 120.],\n",
              "         [131., 121., 131.]],\n",
              "\n",
              "        [[163., 148., 120.],\n",
              "         [158., 148., 122.],\n",
              "         [163., 156., 133.],\n",
              "         ...,\n",
              "         [143., 133., 139.],\n",
              "         [143., 134., 142.],\n",
              "         [143., 133., 144.]]],\n",
              "\n",
              "\n",
              "       [[[255., 255., 255.],\n",
              "         [253., 253., 253.],\n",
              "         [253., 253., 253.],\n",
              "         ...,\n",
              "         [253., 253., 253.],\n",
              "         [253., 253., 253.],\n",
              "         [253., 253., 253.]],\n",
              "\n",
              "        [[255., 255., 255.],\n",
              "         [255., 255., 255.],\n",
              "         [255., 255., 255.],\n",
              "         ...,\n",
              "         [255., 255., 255.],\n",
              "         [255., 255., 255.],\n",
              "         [255., 255., 255.]],\n",
              "\n",
              "        [[255., 255., 255.],\n",
              "         [254., 254., 254.],\n",
              "         [254., 254., 254.],\n",
              "         ...,\n",
              "         [254., 254., 254.],\n",
              "         [254., 254., 254.],\n",
              "         [254., 254., 254.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[113., 120., 112.],\n",
              "         [111., 118., 111.],\n",
              "         [105., 112., 106.],\n",
              "         ...,\n",
              "         [ 72.,  81.,  80.],\n",
              "         [ 72.,  80.,  79.],\n",
              "         [ 72.,  80.,  79.]],\n",
              "\n",
              "        [[111., 118., 110.],\n",
              "         [104., 111., 104.],\n",
              "         [ 99., 106.,  98.],\n",
              "         ...,\n",
              "         [ 68.,  75.,  73.],\n",
              "         [ 70.,  76.,  75.],\n",
              "         [ 78.,  84.,  82.]],\n",
              "\n",
              "        [[106., 113., 105.],\n",
              "         [ 99., 106.,  98.],\n",
              "         [ 95., 102.,  94.],\n",
              "         ...,\n",
              "         [ 78.,  85.,  83.],\n",
              "         [ 79.,  85.,  83.],\n",
              "         [ 80.,  86.,  84.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 35., 178., 235.],\n",
              "         [ 40., 176., 239.],\n",
              "         [ 42., 176., 241.],\n",
              "         ...,\n",
              "         [ 99., 177., 219.],\n",
              "         [ 79., 147., 197.],\n",
              "         [ 89., 148., 189.]],\n",
              "\n",
              "        [[ 57., 182., 234.],\n",
              "         [ 44., 184., 250.],\n",
              "         [ 50., 183., 240.],\n",
              "         ...,\n",
              "         [156., 182., 200.],\n",
              "         [141., 177., 206.],\n",
              "         [116., 149., 175.]],\n",
              "\n",
              "        [[ 98., 197., 237.],\n",
              "         [ 64., 189., 252.],\n",
              "         [ 69., 192., 245.],\n",
              "         ...,\n",
              "         [188., 195., 206.],\n",
              "         [119., 135., 147.],\n",
              "         [ 61.,  79.,  90.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 73.,  79.,  77.],\n",
              "         [ 53.,  63.,  68.],\n",
              "         [ 54.,  68.,  80.],\n",
              "         ...,\n",
              "         [ 17.,  40.,  64.],\n",
              "         [ 21.,  36.,  51.],\n",
              "         [ 33.,  48.,  49.]],\n",
              "\n",
              "        [[ 61.,  68.,  75.],\n",
              "         [ 55.,  70.,  86.],\n",
              "         [ 57.,  79., 103.],\n",
              "         ...,\n",
              "         [ 24.,  48.,  72.],\n",
              "         [ 17.,  35.,  53.],\n",
              "         [  7.,  23.,  32.]],\n",
              "\n",
              "        [[ 44.,  56.,  73.],\n",
              "         [ 46.,  66.,  88.],\n",
              "         [ 49.,  77., 105.],\n",
              "         ...,\n",
              "         [ 27.,  52.,  77.],\n",
              "         [ 21.,  43.,  66.],\n",
              "         [ 12.,  31.,  50.]]],\n",
              "\n",
              "\n",
              "       [[[189., 211., 240.],\n",
              "         [186., 208., 236.],\n",
              "         [185., 207., 235.],\n",
              "         ...,\n",
              "         [175., 195., 224.],\n",
              "         [172., 194., 222.],\n",
              "         [169., 194., 220.]],\n",
              "\n",
              "        [[194., 210., 239.],\n",
              "         [191., 207., 236.],\n",
              "         [190., 206., 235.],\n",
              "         ...,\n",
              "         [173., 192., 220.],\n",
              "         [171., 191., 218.],\n",
              "         [167., 190., 216.]],\n",
              "\n",
              "        [[208., 219., 244.],\n",
              "         [205., 216., 240.],\n",
              "         [204., 215., 239.],\n",
              "         ...,\n",
              "         [175., 191., 217.],\n",
              "         [172., 190., 216.],\n",
              "         [169., 191., 215.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[207., 199., 181.],\n",
              "         [203., 195., 175.],\n",
              "         [203., 196., 173.],\n",
              "         ...,\n",
              "         [135., 132., 127.],\n",
              "         [162., 158., 150.],\n",
              "         [168., 163., 151.]],\n",
              "\n",
              "        [[198., 190., 170.],\n",
              "         [189., 181., 159.],\n",
              "         [180., 172., 147.],\n",
              "         ...,\n",
              "         [178., 171., 160.],\n",
              "         [175., 169., 156.],\n",
              "         [175., 169., 154.]],\n",
              "\n",
              "        [[198., 189., 173.],\n",
              "         [189., 181., 162.],\n",
              "         [178., 170., 149.],\n",
              "         ...,\n",
              "         [195., 184., 169.],\n",
              "         [196., 189., 171.],\n",
              "         [195., 190., 171.]]],\n",
              "\n",
              "\n",
              "       [[[229., 229., 239.],\n",
              "         [236., 237., 247.],\n",
              "         [234., 236., 247.],\n",
              "         ...,\n",
              "         [217., 219., 233.],\n",
              "         [221., 223., 234.],\n",
              "         [222., 223., 233.]],\n",
              "\n",
              "        [[222., 221., 229.],\n",
              "         [239., 239., 249.],\n",
              "         [233., 234., 246.],\n",
              "         ...,\n",
              "         [223., 223., 236.],\n",
              "         [227., 228., 238.],\n",
              "         [210., 211., 220.]],\n",
              "\n",
              "        [[213., 206., 211.],\n",
              "         [234., 232., 239.],\n",
              "         [231., 233., 244.],\n",
              "         ...,\n",
              "         [220., 220., 232.],\n",
              "         [220., 219., 232.],\n",
              "         [202., 203., 215.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[150., 143., 135.],\n",
              "         [140., 135., 127.],\n",
              "         [132., 127., 120.],\n",
              "         ...,\n",
              "         [224., 222., 218.],\n",
              "         [230., 228., 225.],\n",
              "         [241., 241., 238.]],\n",
              "\n",
              "        [[137., 132., 126.],\n",
              "         [130., 127., 120.],\n",
              "         [125., 121., 115.],\n",
              "         ...,\n",
              "         [181., 180., 178.],\n",
              "         [202., 201., 198.],\n",
              "         [212., 211., 207.]],\n",
              "\n",
              "        [[122., 119., 114.],\n",
              "         [118., 116., 110.],\n",
              "         [120., 116., 111.],\n",
              "         ...,\n",
              "         [179., 177., 173.],\n",
              "         [164., 164., 162.],\n",
              "         [163., 163., 161.]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJBVK0tJHVNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = x_train.shape[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg8lqDXFHlXX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "c46bca5b-a421-4160-adf2-eba60af492a3"
      },
      "source": [
        "#building the model\n",
        "cnn = tf.keras.Sequential()\n",
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape = input_shape))\n",
        "cnn.add(tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(2,2))\n",
        "cnn.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'))\n",
        "cnn.add(tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(2,2))\n",
        "cnn.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "\n",
        "cnn.add(tf.keras.layers.Dense(1024, activation = 'relu'))\n",
        "cnn.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "cnn.add(tf.keras.layers.Dense(1024, activation = 'relu'))\n",
        "\n",
        "cnn.add(tf.keras.layers.Dense(10, activation = 'softmax'))\n",
        "cnn.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 10, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              1639424   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 2,764,842\n",
            "Trainable params: 2,764,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkd5goYJItTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.compile(optimizer = tf.keras.optimizers.RMSprop(0.0001, decay = 1e-6), loss ='categorical_crossentropy', metrics =['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uszBZ8fhIyxl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0dda0815-cca1-4c76-d01c-c3dc7d7096ca"
      },
      "source": [
        "epochs = 100\n",
        "\n",
        "history = cnn.fit(x_train, y_train, batch_size =512, epochs = epochs)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples\n",
            "Epoch 1/100\n",
            "50000/50000 [==============================] - 5s 97us/sample - loss: 1.1301 - acc: 0.6018\n",
            "Epoch 2/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 1.0997 - acc: 0.6111\n",
            "Epoch 3/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 1.0776 - acc: 0.6200\n",
            "Epoch 4/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 1.0593 - acc: 0.6283\n",
            "Epoch 5/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 1.0343 - acc: 0.6352\n",
            "Epoch 6/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 1.0138 - acc: 0.6437\n",
            "Epoch 7/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 1.0027 - acc: 0.6476\n",
            "Epoch 8/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.9720 - acc: 0.6569\n",
            "Epoch 9/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.9587 - acc: 0.6636\n",
            "Epoch 10/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.9442 - acc: 0.6674\n",
            "Epoch 11/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.9274 - acc: 0.6724\n",
            "Epoch 12/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.9116 - acc: 0.6798\n",
            "Epoch 13/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.8984 - acc: 0.6844\n",
            "Epoch 14/100\n",
            "50000/50000 [==============================] - 4s 86us/sample - loss: 0.8778 - acc: 0.6907\n",
            "Epoch 15/100\n",
            "50000/50000 [==============================] - 4s 86us/sample - loss: 0.8667 - acc: 0.6928\n",
            "Epoch 16/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.8540 - acc: 0.6983\n",
            "Epoch 17/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.8435 - acc: 0.7021\n",
            "Epoch 18/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.8271 - acc: 0.7089\n",
            "Epoch 19/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.8103 - acc: 0.7154\n",
            "Epoch 20/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.7990 - acc: 0.7167\n",
            "Epoch 21/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.7869 - acc: 0.7239\n",
            "Epoch 22/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.7715 - acc: 0.7293\n",
            "Epoch 23/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.7608 - acc: 0.7308\n",
            "Epoch 24/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.7555 - acc: 0.7346\n",
            "Epoch 25/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.7388 - acc: 0.7398\n",
            "Epoch 26/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.7327 - acc: 0.7408\n",
            "Epoch 27/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.7185 - acc: 0.7454\n",
            "Epoch 28/100\n",
            "50000/50000 [==============================] - 4s 86us/sample - loss: 0.7076 - acc: 0.7506\n",
            "Epoch 29/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.6973 - acc: 0.7524\n",
            "Epoch 30/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.6816 - acc: 0.7592\n",
            "Epoch 31/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.6704 - acc: 0.7625\n",
            "Epoch 32/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.6653 - acc: 0.7641\n",
            "Epoch 33/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.6554 - acc: 0.7681\n",
            "Epoch 34/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.6470 - acc: 0.7718\n",
            "Epoch 35/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.6339 - acc: 0.7752\n",
            "Epoch 36/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.6283 - acc: 0.7778\n",
            "Epoch 37/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.6172 - acc: 0.7826\n",
            "Epoch 38/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.6051 - acc: 0.7860\n",
            "Epoch 39/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.6028 - acc: 0.7879\n",
            "Epoch 40/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.5915 - acc: 0.7916\n",
            "Epoch 41/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.5793 - acc: 0.7958\n",
            "Epoch 42/100\n",
            "50000/50000 [==============================] - 4s 89us/sample - loss: 0.5693 - acc: 0.7984\n",
            "Epoch 43/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.5615 - acc: 0.8023\n",
            "Epoch 44/100\n",
            "50000/50000 [==============================] - 4s 89us/sample - loss: 0.5538 - acc: 0.8059\n",
            "Epoch 45/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.5457 - acc: 0.8058\n",
            "Epoch 46/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.5428 - acc: 0.8075\n",
            "Epoch 47/100\n",
            "50000/50000 [==============================] - 4s 89us/sample - loss: 0.5280 - acc: 0.8130\n",
            "Epoch 48/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.5235 - acc: 0.8151\n",
            "Epoch 49/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.5158 - acc: 0.8171\n",
            "Epoch 50/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.5090 - acc: 0.8204\n",
            "Epoch 51/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.5028 - acc: 0.8204\n",
            "Epoch 52/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.4921 - acc: 0.8256\n",
            "Epoch 53/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.4853 - acc: 0.8283\n",
            "Epoch 54/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.4761 - acc: 0.8314\n",
            "Epoch 55/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.4707 - acc: 0.8328\n",
            "Epoch 56/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.4641 - acc: 0.8340\n",
            "Epoch 57/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.4561 - acc: 0.8396\n",
            "Epoch 58/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.4536 - acc: 0.8391\n",
            "Epoch 59/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.4462 - acc: 0.8416\n",
            "Epoch 60/100\n",
            "50000/50000 [==============================] - 4s 89us/sample - loss: 0.4368 - acc: 0.8444\n",
            "Epoch 61/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.4267 - acc: 0.8484\n",
            "Epoch 62/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.4276 - acc: 0.8486\n",
            "Epoch 63/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.4219 - acc: 0.8496\n",
            "Epoch 64/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.4159 - acc: 0.8521\n",
            "Epoch 65/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.4073 - acc: 0.8565\n",
            "Epoch 66/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.3980 - acc: 0.8591\n",
            "Epoch 67/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.3946 - acc: 0.8593\n",
            "Epoch 68/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.3894 - acc: 0.8616\n",
            "Epoch 69/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.3889 - acc: 0.8608\n",
            "Epoch 70/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.3790 - acc: 0.8668\n",
            "Epoch 71/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.3758 - acc: 0.8657\n",
            "Epoch 72/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.3671 - acc: 0.8684\n",
            "Epoch 73/100\n",
            "50000/50000 [==============================] - 4s 87us/sample - loss: 0.3648 - acc: 0.8703\n",
            "Epoch 74/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.3570 - acc: 0.8718\n",
            "Epoch 75/100\n",
            "50000/50000 [==============================] - 4s 89us/sample - loss: 0.3539 - acc: 0.8743\n",
            "Epoch 76/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.3467 - acc: 0.8760\n",
            "Epoch 77/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.3435 - acc: 0.8784\n",
            "Epoch 78/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.3422 - acc: 0.8787\n",
            "Epoch 79/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.3359 - acc: 0.8812\n",
            "Epoch 80/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.3320 - acc: 0.8820\n",
            "Epoch 81/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.3252 - acc: 0.8835\n",
            "Epoch 82/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.3220 - acc: 0.8853\n",
            "Epoch 83/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.3191 - acc: 0.8865\n",
            "Epoch 84/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.3080 - acc: 0.8915\n",
            "Epoch 85/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.3059 - acc: 0.8915\n",
            "Epoch 86/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.3038 - acc: 0.8922\n",
            "Epoch 87/100\n",
            "50000/50000 [==============================] - 4s 89us/sample - loss: 0.2981 - acc: 0.8944\n",
            "Epoch 88/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.2998 - acc: 0.8933\n",
            "Epoch 89/100\n",
            "50000/50000 [==============================] - 4s 89us/sample - loss: 0.2895 - acc: 0.8980\n",
            "Epoch 90/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.2868 - acc: 0.8969\n",
            "Epoch 91/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.2846 - acc: 0.8982\n",
            "Epoch 92/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.2734 - acc: 0.9036\n",
            "Epoch 93/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.2785 - acc: 0.9022\n",
            "Epoch 94/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.2703 - acc: 0.9034\n",
            "Epoch 95/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.2703 - acc: 0.9032\n",
            "Epoch 96/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.2712 - acc: 0.9038\n",
            "Epoch 97/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.2560 - acc: 0.9091\n",
            "Epoch 98/100\n",
            "50000/50000 [==============================] - 4s 89us/sample - loss: 0.2614 - acc: 0.9068\n",
            "Epoch 99/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.2517 - acc: 0.9108\n",
            "Epoch 100/100\n",
            "50000/50000 [==============================] - 4s 88us/sample - loss: 0.2531 - acc: 0.9096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi_MV6GjNuHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_classes = cnn.predict_classes(x_test) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VXmwAoEI2yb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b83cbac2-b701-4dfd-c576-0cf44e9d24ff"
      },
      "source": [
        "#checking the accuracy\n",
        "evaluation = cnn.evaluate(x_test, y_test)\n",
        "print('Test Accuracy: {}'.format(evaluation[1]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 108us/sample - loss: 3.9989 - acc: 0.1000\n",
            "Test Accuracy: 0.10000000149011612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeV3BXq0KbW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}